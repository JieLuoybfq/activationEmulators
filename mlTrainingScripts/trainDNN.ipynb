{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 21)\n",
      "(14000, 21)\n",
      "(2000, 21)\n",
      "(3999, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>smax</th>\n",
       "      <th>actFrac</th>\n",
       "      <th>Log10N</th>\n",
       "      <th>Log10ug</th>\n",
       "      <th>Sigma_g</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Log10V</th>\n",
       "      <th>T</th>\n",
       "      <th>P</th>\n",
       "      <th>...</th>\n",
       "      <th>smaxes_arg</th>\n",
       "      <th>actFrac_arg</th>\n",
       "      <th>smaxes_mbn</th>\n",
       "      <th>actFrac_mbn</th>\n",
       "      <th>logTSmax</th>\n",
       "      <th>Smax_Twomey</th>\n",
       "      <th>actFrac_Twomey</th>\n",
       "      <th>delta_smax</th>\n",
       "      <th>delta_actFrac</th>\n",
       "      <th>d_arg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3.999000e+03</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.999000e+03</td>\n",
       "      <td>3.999000e+03</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3.999000e+03</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17999.000000</td>\n",
       "      <td>4.646786e-03</td>\n",
       "      <td>0.580321</td>\n",
       "      <td>3.047198</td>\n",
       "      <td>-0.183120</td>\n",
       "      <td>1.701575</td>\n",
       "      <td>0.611031</td>\n",
       "      <td>0.041027</td>\n",
       "      <td>278.907836</td>\n",
       "      <td>77425.604214</td>\n",
       "      <td>...</td>\n",
       "      <td>3.479813e-03</td>\n",
       "      <td>6.157842e-01</td>\n",
       "      <td>0.041887</td>\n",
       "      <td>7.590068e-01</td>\n",
       "      <td>-4.152635</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>0.380439</td>\n",
       "      <td>-0.012541</td>\n",
       "      <td>0.199882</td>\n",
       "      <td>-3.546342e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1154.556192</td>\n",
       "      <td>1.366043e-02</td>\n",
       "      <td>0.395539</td>\n",
       "      <td>0.858499</td>\n",
       "      <td>1.154843</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.348092</td>\n",
       "      <td>0.860864</td>\n",
       "      <td>17.826408</td>\n",
       "      <td>15965.902148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.226498e-02</td>\n",
       "      <td>3.859532e-01</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>3.739101e-01</td>\n",
       "      <td>0.191402</td>\n",
       "      <td>0.012985</td>\n",
       "      <td>0.389884</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>0.500056</td>\n",
       "      <td>7.723558e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16000.000000</td>\n",
       "      <td>3.695723e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004350</td>\n",
       "      <td>-2.997400</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-1.998350</td>\n",
       "      <td>248.009300</td>\n",
       "      <td>50002.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.243701e-08</td>\n",
       "      <td>8.194802e-14</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>5.607000e-10</td>\n",
       "      <td>-4.365845</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>-0.040491</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-3.706159e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16999.500000</td>\n",
       "      <td>3.374548e-06</td>\n",
       "      <td>0.127047</td>\n",
       "      <td>2.456800</td>\n",
       "      <td>-0.973600</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.308520</td>\n",
       "      <td>-0.557150</td>\n",
       "      <td>263.323300</td>\n",
       "      <td>63345.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.135225e-06</td>\n",
       "      <td>2.056460e-01</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>5.600813e-01</td>\n",
       "      <td>-4.314108</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.068813</td>\n",
       "      <td>-0.027372</td>\n",
       "      <td>-0.049230</td>\n",
       "      <td>-6.741039e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17999.000000</td>\n",
       "      <td>2.748513e-05</td>\n",
       "      <td>0.714462</td>\n",
       "      <td>3.349136</td>\n",
       "      <td>0.296293</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.615420</td>\n",
       "      <td>0.341101</td>\n",
       "      <td>278.959700</td>\n",
       "      <td>77535.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.719518e-05</td>\n",
       "      <td>7.831628e-01</td>\n",
       "      <td>0.009433</td>\n",
       "      <td>9.984992e-01</td>\n",
       "      <td>-4.219352</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>0.155595</td>\n",
       "      <td>-0.012201</td>\n",
       "      <td>0.119450</td>\n",
       "      <td>-1.199510e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18998.500000</td>\n",
       "      <td>1.982735e-03</td>\n",
       "      <td>0.969114</td>\n",
       "      <td>3.762620</td>\n",
       "      <td>0.756669</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.916920</td>\n",
       "      <td>0.767278</td>\n",
       "      <td>294.186900</td>\n",
       "      <td>91195.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.395455e-03</td>\n",
       "      <td>9.660376e-01</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-4.019638</td>\n",
       "      <td>0.028978</td>\n",
       "      <td>0.890275</td>\n",
       "      <td>-0.001220</td>\n",
       "      <td>0.678972</td>\n",
       "      <td>4.512024e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19998.000000</td>\n",
       "      <td>2.043627e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.999761</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>309.953500</td>\n",
       "      <td>104991.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.284354e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.699205</td>\n",
       "      <td>0.040505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196058</td>\n",
       "      <td>0.933352</td>\n",
       "      <td>3.127878e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              index          smax      actFrac       Log10N      Log10ug  \\\n",
       "count   3999.000000  3.999000e+03  3999.000000  3999.000000  3999.000000   \n",
       "mean   17999.000000  4.646786e-03     0.580321     3.047198    -0.183120   \n",
       "std     1154.556192  1.366043e-02     0.395539     0.858499     1.154843   \n",
       "min    16000.000000  3.695723e-09     0.000000     1.004350    -2.997400   \n",
       "25%    16999.500000  3.374548e-06     0.127047     2.456800    -0.973600   \n",
       "50%    17999.000000  2.748513e-05     0.714462     3.349136     0.296293   \n",
       "75%    18998.500000  1.982735e-03     0.969114     3.762620     0.756669   \n",
       "max    19998.000000  2.043627e-01     1.000000     3.999761     0.999978   \n",
       "\n",
       "           Sigma_g        Kappa       Log10V            T              P  ...  \\\n",
       "count  3999.000000  3999.000000  3999.000000  3999.000000    3999.000000  ...   \n",
       "mean      1.701575     0.611031     0.041027   278.907836   77425.604214  ...   \n",
       "std       0.100000     0.348092     0.860864    17.826408   15965.902148  ...   \n",
       "min       1.600000     0.000060    -1.998350   248.009300   50002.750000  ...   \n",
       "25%       1.600000     0.308520    -0.557150   263.323300   63345.750000  ...   \n",
       "50%       1.800000     0.615420     0.341101   278.959700   77535.750000  ...   \n",
       "75%       1.800000     0.916920     0.767278   294.186900   91195.000000  ...   \n",
       "max       1.800000     1.199700     0.999978   309.953500  104991.750000  ...   \n",
       "\n",
       "         smaxes_arg   actFrac_arg   smaxes_mbn   actFrac_mbn     logTSmax  \\\n",
       "count  3.999000e+03  3.999000e+03  3999.000000  3.999000e+03  3999.000000   \n",
       "mean   3.479813e-03  6.157842e-01     0.041887  7.590068e-01    -4.152635   \n",
       "std    1.226498e-02  3.859532e-01     0.046342  3.739101e-01     0.191402   \n",
       "min    2.243701e-08  8.194802e-14     0.000010  5.607000e-10    -4.365845   \n",
       "25%    4.135225e-06  2.056460e-01     0.000129  5.600813e-01    -4.314108   \n",
       "50%    2.719518e-05  7.831628e-01     0.009433  9.984992e-01    -4.219352   \n",
       "75%    1.395455e-03  9.660376e-01     0.100000  1.000000e+00    -4.019638   \n",
       "max    2.284354e-01  1.000000e+00     0.100000  1.000000e+00    -3.699205   \n",
       "\n",
       "       Smax_Twomey  actFrac_Twomey   delta_smax  delta_actFrac         d_arg  \n",
       "count  3999.000000     3999.000000  3999.000000    3999.000000  3.999000e+03  \n",
       "mean      0.017188        0.380439    -0.012541       0.199882 -3.546342e-02  \n",
       "std       0.012985        0.389884     0.018931       0.500056  7.723558e-02  \n",
       "min       0.000541        0.010141    -0.040491      -1.000000 -3.706159e-01  \n",
       "25%       0.004308        0.068813    -0.027372      -0.049230 -6.741039e-02  \n",
       "50%       0.015693        0.155595    -0.012201       0.119450 -1.199510e-13  \n",
       "75%       0.028978        0.890275    -0.001220       0.678972  4.512024e-03  \n",
       "max       0.040505        1.000000     0.196058       0.933352  3.127878e-01  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up the data\n",
    "data_file = pd.read_csv('parcelOutput250BinsWithTwomey_111920.csv')\n",
    "data_file = data_file.reset_index()\n",
    "data_file = data_file.apply(pd.to_numeric)\n",
    "data_file['d_arg'] = data_file['actFrac'] - data_file['actFrac_arg']\n",
    "\n",
    "data_file_gen = pd.read_csv('parcelOutput250BinsWithTwomeyPlus4K_111920.csv')\n",
    "data_file_gen = data_file_gen.reset_index()\n",
    "data_file_gen = data_file_gen.apply(pd.to_numeric)\n",
    "data_file_gen['d_arg'] = data_file_gen['actFrac'] - data_file_gen['actFrac_arg']\n",
    "\n",
    "data_file_sens = pd.read_csv('parcelOutput250BinsWithTwomeySens_111920.csv')\n",
    "data_file_sens = data_file_sens.reset_index()\n",
    "data_file_sens = data_file_sens.apply(pd.to_numeric)\n",
    "data_file_sens['d_arg'] = data_file_sens['actFrac'] - data_file_sens['actFrac_arg']\n",
    "\n",
    "print(data_file.shape)\n",
    "\n",
    "data_file_train = data_file[data_file['index'] < 14000]\n",
    "data_file_val = data_file[(data_file['index'] >= 14000) & (data_file['index'] < 16000)]\n",
    "data_file_test = data_file[data_file['index'] >= 16000]\n",
    "\n",
    "print(data_file_train.shape)\n",
    "print(data_file_val.shape)\n",
    "print(data_file_test.shape)\n",
    "\n",
    "data_file_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 10)\n",
      "(14000,)\n"
     ]
    }
   ],
   "source": [
    "# Do data preprocessing\n",
    "varN = ['Log10N', 'Log10ug', 'Sigma_g', 'Kappa', 'Log10V', 'T', 'P', 'ac', 'actFrac_arg','smaxes_arg']\n",
    "#d_arg: ARG, delta_actFrac: Twomey, actFrac: Naive\n",
    "predVar = 'd_arg'\n",
    "X_train = (data_file_train[varN].values - np.nanmean(data_file_train[varN].values, axis=0))/ np.nanstd(data_file_train[varN].values, axis=0)\n",
    "Y_train = (data_file_train[predVar].values - np.nanmean(data_file_train[predVar].values, axis=0))/ np.nanstd(data_file_train[predVar].values, axis=0)\n",
    "#Y_train = data_file_train[predVar].values\n",
    "\n",
    "X_test = (data_file_test[varN].values - np.nanmean(data_file_train[varN].values, axis=0))/ np.nanstd(data_file_train[varN].values, axis=0)\n",
    "Y_test = (data_file_test[predVar].values - np.nanmean(data_file_train[predVar].values, axis=0))/ np.nanstd(data_file_train[predVar].values, axis=0)\n",
    "#Y_test = data_file_test[predVar].values\n",
    "\n",
    "\n",
    "X_val = (data_file_val[varN].values - np.nanmean(data_file_train[varN].values, axis=0))/ np.nanstd(data_file_train[varN].values, axis=0)\n",
    "Y_val = (data_file_val[predVar].values - np.nanmean(data_file_train[predVar].values, axis=0))/ np.nanstd(data_file_train[predVar].values, axis=0)\n",
    "#Y_val = data_file_val[predVar].values\n",
    "\n",
    "X_gen = (data_file_gen[varN].values - np.nanmean(data_file_train[varN].values, axis=0))/ np.nanstd(data_file_train[varN].values, axis=0)\n",
    "Y_gen = (data_file_gen[predVar].values - np.nanmean(data_file_train[predVar].values, axis=0))/ np.nanstd(data_file_train[predVar].values, axis=0)\n",
    "Y_gen = data_file_gen[predVar].values\n",
    "\n",
    "X_sens = (data_file_sens[varN].values - np.nanmean(data_file_train[varN].values, axis=0))/ np.nanstd(data_file_train[varN].values, axis=0)\n",
    "Y_sens = (data_file_sens[predVar].values - np.nanmean(data_file_train[predVar].values, axis=0))/ np.nanstd(data_file_train[predVar].values, axis=0)\n",
    "Y_sens = data_file_sens[predVar].values\n",
    "\n",
    "Y_train_stds = np.nanstd(data_file_train[predVar].values, axis=0)\n",
    "Y_train_means = np.nanmean(data_file_train[predVar].values, axis=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "tf.random.set_seed(72520)\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(50, input_dim=10, activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(30, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 8,711\n",
      "Trainable params: 8,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the DNN\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate = 1e-3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 2000 samples\n",
      "Epoch 1/147\n",
      "14000/14000 [==============================] - 1s 57us/sample - loss: 0.6433 - val_loss: 0.3715\n",
      "Epoch 2/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.3927 - val_loss: 0.2712\n",
      "Epoch 3/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.3067 - val_loss: 0.2236\n",
      "Epoch 4/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.2475 - val_loss: 0.1831\n",
      "Epoch 5/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.2139 - val_loss: 0.1373\n",
      "Epoch 6/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.1813 - val_loss: 0.1128\n",
      "Epoch 7/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.1605 - val_loss: 0.0922\n",
      "Epoch 8/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.1436 - val_loss: 0.0969\n",
      "Epoch 9/147\n",
      "14000/14000 [==============================] - 0s 24us/sample - loss: 0.1334 - val_loss: 0.0765\n",
      "Epoch 10/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.1261 - val_loss: 0.0712\n",
      "Epoch 11/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.1202 - val_loss: 0.0657\n",
      "Epoch 12/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.1132 - val_loss: 0.0646\n",
      "Epoch 13/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.1119 - val_loss: 0.0700\n",
      "Epoch 14/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.1056 - val_loss: 0.0587\n",
      "Epoch 15/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.1024 - val_loss: 0.0583\n",
      "Epoch 16/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.1010 - val_loss: 0.0647\n",
      "Epoch 17/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0988 - val_loss: 0.0604\n",
      "Epoch 18/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.1010 - val_loss: 0.0565\n",
      "Epoch 19/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0998 - val_loss: 0.0577\n",
      "Epoch 20/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0944 - val_loss: 0.0545\n",
      "Epoch 21/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0935 - val_loss: 0.0583\n",
      "Epoch 22/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0962 - val_loss: 0.0536\n",
      "Epoch 23/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0924 - val_loss: 0.0522\n",
      "Epoch 24/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0880 - val_loss: 0.0565\n",
      "Epoch 25/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0885 - val_loss: 0.0538\n",
      "Epoch 26/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0857 - val_loss: 0.0503\n",
      "Epoch 27/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0849 - val_loss: 0.0530\n",
      "Epoch 28/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0830 - val_loss: 0.0471\n",
      "Epoch 29/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0837 - val_loss: 0.0482\n",
      "Epoch 30/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0864 - val_loss: 0.0495\n",
      "Epoch 31/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0830 - val_loss: 0.0499\n",
      "Epoch 32/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0812 - val_loss: 0.0497\n",
      "Epoch 33/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0817 - val_loss: 0.0488\n",
      "Epoch 34/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0782 - val_loss: 0.0472\n",
      "Epoch 35/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0788 - val_loss: 0.0470\n",
      "Epoch 36/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0802 - val_loss: 0.0493\n",
      "Epoch 37/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0775 - val_loss: 0.0464\n",
      "Epoch 38/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0758 - val_loss: 0.0465\n",
      "Epoch 39/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0755 - val_loss: 0.0470\n",
      "Epoch 40/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0767 - val_loss: 0.0435\n",
      "Epoch 41/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0767 - val_loss: 0.0431\n",
      "Epoch 42/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0776 - val_loss: 0.0452\n",
      "Epoch 43/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0750 - val_loss: 0.0445\n",
      "Epoch 44/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0743 - val_loss: 0.0495\n",
      "Epoch 45/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0735 - val_loss: 0.0481\n",
      "Epoch 46/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0709 - val_loss: 0.0491\n",
      "Epoch 47/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0739 - val_loss: 0.0443\n",
      "Epoch 48/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0736 - val_loss: 0.0461\n",
      "Epoch 49/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0723 - val_loss: 0.0434\n",
      "Epoch 50/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0686 - val_loss: 0.0458\n",
      "Epoch 51/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0707 - val_loss: 0.0427\n",
      "Epoch 52/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0719 - val_loss: 0.0509\n",
      "Epoch 53/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0713 - val_loss: 0.0447\n",
      "Epoch 54/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0726 - val_loss: 0.0423\n",
      "Epoch 55/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0721 - val_loss: 0.0435\n",
      "Epoch 56/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0691 - val_loss: 0.0463\n",
      "Epoch 57/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0700 - val_loss: 0.0454\n",
      "Epoch 58/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0688 - val_loss: 0.0426\n",
      "Epoch 59/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0708 - val_loss: 0.0438\n",
      "Epoch 60/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0661 - val_loss: 0.0438\n",
      "Epoch 61/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0694 - val_loss: 0.0439\n",
      "Epoch 62/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0691 - val_loss: 0.0431\n",
      "Epoch 63/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0695 - val_loss: 0.0434\n",
      "Epoch 64/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0675 - val_loss: 0.0421\n",
      "Epoch 65/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0666 - val_loss: 0.0469\n",
      "Epoch 66/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0680 - val_loss: 0.0452\n",
      "Epoch 67/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0666 - val_loss: 0.0472\n",
      "Epoch 68/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0673 - val_loss: 0.0437\n",
      "Epoch 69/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0659 - val_loss: 0.0454\n",
      "Epoch 70/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0642 - val_loss: 0.0423\n",
      "Epoch 71/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0657 - val_loss: 0.0416\n",
      "Epoch 72/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0654 - val_loss: 0.0417\n",
      "Epoch 73/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0638 - val_loss: 0.0443\n",
      "Epoch 74/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0656 - val_loss: 0.0448\n",
      "Epoch 75/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0637 - val_loss: 0.0453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0660 - val_loss: 0.0464\n",
      "Epoch 77/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0658 - val_loss: 0.0401\n",
      "Epoch 78/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0614 - val_loss: 0.0418\n",
      "Epoch 79/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0631 - val_loss: 0.0441\n",
      "Epoch 80/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0634 - val_loss: 0.0385\n",
      "Epoch 81/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0658 - val_loss: 0.0385\n",
      "Epoch 82/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0616 - val_loss: 0.0410\n",
      "Epoch 83/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0642 - val_loss: 0.0453\n",
      "Epoch 84/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0639 - val_loss: 0.0437\n",
      "Epoch 85/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0635 - val_loss: 0.0456\n",
      "Epoch 86/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0650 - val_loss: 0.0427\n",
      "Epoch 87/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0622 - val_loss: 0.0458\n",
      "Epoch 88/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0611 - val_loss: 0.0436\n",
      "Epoch 89/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0642 - val_loss: 0.0440\n",
      "Epoch 90/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0621 - val_loss: 0.0427\n",
      "Epoch 91/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0633 - val_loss: 0.0419\n",
      "Epoch 92/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0609 - val_loss: 0.0420\n",
      "Epoch 93/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0612 - val_loss: 0.0432\n",
      "Epoch 94/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0632 - val_loss: 0.0420\n",
      "Epoch 95/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0618 - val_loss: 0.0427\n",
      "Epoch 96/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0637 - val_loss: 0.0397\n",
      "Epoch 97/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0608 - val_loss: 0.0402\n",
      "Epoch 98/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0621 - val_loss: 0.0398\n",
      "Epoch 99/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0630 - val_loss: 0.0389\n",
      "Epoch 100/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0607 - val_loss: 0.0387\n",
      "Epoch 101/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0597 - val_loss: 0.0403\n",
      "Epoch 102/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0599 - val_loss: 0.0363\n",
      "Epoch 103/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0613 - val_loss: 0.0373\n",
      "Epoch 104/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0630 - val_loss: 0.0405\n",
      "Epoch 105/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0602 - val_loss: 0.0394\n",
      "Epoch 106/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0622 - val_loss: 0.0409\n",
      "Epoch 107/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0616 - val_loss: 0.0364\n",
      "Epoch 108/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0610 - val_loss: 0.0405\n",
      "Epoch 109/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0623 - val_loss: 0.0392\n",
      "Epoch 110/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0598 - val_loss: 0.0427\n",
      "Epoch 111/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0607 - val_loss: 0.0382\n",
      "Epoch 112/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0613 - val_loss: 0.0408\n",
      "Epoch 113/147\n",
      "14000/14000 [==============================] - 0s 23us/sample - loss: 0.0625 - val_loss: 0.0419\n",
      "Epoch 114/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0593 - val_loss: 0.0379\n",
      "Epoch 115/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0568 - val_loss: 0.0385\n",
      "Epoch 116/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0618 - val_loss: 0.0368\n",
      "Epoch 117/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0608 - val_loss: 0.0404\n",
      "Epoch 118/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0612 - val_loss: 0.0386\n",
      "Epoch 119/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0615 - val_loss: 0.0372\n",
      "Epoch 120/147\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.062 - 0s 22us/sample - loss: 0.0636 - val_loss: 0.0373\n",
      "Epoch 121/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0598 - val_loss: 0.0385\n",
      "Epoch 122/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0609 - val_loss: 0.0369\n",
      "Epoch 123/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0557 - val_loss: 0.0370\n",
      "Epoch 124/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0571 - val_loss: 0.0411\n",
      "Epoch 125/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0593 - val_loss: 0.0355\n",
      "Epoch 126/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0583 - val_loss: 0.0368\n",
      "Epoch 127/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0619 - val_loss: 0.0369\n",
      "Epoch 128/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0616 - val_loss: 0.0408\n",
      "Epoch 129/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0598 - val_loss: 0.0414\n",
      "Epoch 130/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0606 - val_loss: 0.0387\n",
      "Epoch 131/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0585 - val_loss: 0.0411\n",
      "Epoch 132/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0586 - val_loss: 0.0425\n",
      "Epoch 133/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0581 - val_loss: 0.0356\n",
      "Epoch 134/147\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.057 - 0s 22us/sample - loss: 0.0578 - val_loss: 0.0392\n",
      "Epoch 135/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0590 - val_loss: 0.0418\n",
      "Epoch 136/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0588 - val_loss: 0.0413\n",
      "Epoch 137/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0578 - val_loss: 0.0370\n",
      "Epoch 138/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0587 - val_loss: 0.0392\n",
      "Epoch 139/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0600 - val_loss: 0.0379\n",
      "Epoch 140/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0587 - val_loss: 0.0407\n",
      "Epoch 141/147\n",
      "14000/14000 [==============================] - 0s 21us/sample - loss: 0.0590 - val_loss: 0.0390\n",
      "Epoch 142/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0581 - val_loss: 0.0386\n",
      "Epoch 143/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0568 - val_loss: 0.0409\n",
      "Epoch 144/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0573 - val_loss: 0.0383\n",
      "Epoch 145/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0594 - val_loss: 0.0412\n",
      "Epoch 146/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0568 - val_loss: 0.0372\n",
      "Epoch 147/147\n",
      "14000/14000 [==============================] - 0s 22us/sample - loss: 0.0587 - val_loss: 0.0366\n"
     ]
    }
   ],
   "source": [
    "# Train the DNN\n",
    "history = model.fit(X_train, Y_train, validation_data = (X_val,Y_val), epochs=147, batch_size=64,\n",
    "                                callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActFrac:  MSE = 0.036622040057570214 R2 = 0.9649470421736052\n"
     ]
    }
   ],
   "source": [
    "# Evaluate training \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print('ActFrac: ', 'MSE =', \n",
    "      mean_squared_error(Y_val, model.predict(X_val)),\n",
    "      'R2 =', r2_score(Y_val,model.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ffaf152fe50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a prediction on the test set\n",
    "predVals = np.concatenate(model.predict(X_test)*Y_train_stds + Y_train_means) + data_file_test['actFrac_arg'].values\n",
    "trueVals = (Y_test*Y_train_stds + Y_train_means) + data_file_test['actFrac_arg'].values\n",
    "plt.scatter(trueVals,predVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
